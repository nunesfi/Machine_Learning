{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/nunesfi/Desktop/IA/env_ia/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /home/nunesfi/Desktop/IA/env_ia/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/nunesfi/Desktop/IA/env_ia/lib/python3.10/site-packages (from nltk) (2024.4.28)\n",
      "Requirement already satisfied: joblib in /home/nunesfi/Desktop/IA/env_ia/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: tqdm in /home/nunesfi/Desktop/IA/env_ia/lib/python3.10/site-packages (from nltk) (4.66.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/nunesfi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = [('eu sou admirada por muitos','alegria'),\n",
    "        ('me sinto completamente amado','alegria'),\n",
    "        ('amar e maravilhoso','alegria'),\n",
    "        ('estou me sentindo muito animado novamente','alegria'),\n",
    "        ('eu estou muito bem hoje','alegria'),\n",
    "        ('que belo dia para dirigir um carro novo','alegria'),\n",
    "        ('o dia está muito bonito','alegria'),\n",
    "        ('estou contente com o resultado do teste que fiz no dia de ontem','alegria'),\n",
    "        ('o amor e lindo','alegria'),\n",
    "        ('nossa amizade e amor vai durar para sempre', 'alegria'),\n",
    "        ('estou amedrontado', 'medo'),\n",
    "        ('ele esta me ameacando a dias', 'medo'),\n",
    "        ('isso me deixa apavorada', 'medo'),\n",
    "        ('este lugar e apavorante', 'medo'),\n",
    "        ('se perdermos outro jogo seremos eliminados e isso me deixa com pavor', 'medo'),\n",
    "        ('tome cuidado com o lobisomem', 'medo'),\n",
    "        ('se eles descobrirem estamos encrencados', 'medo'),\n",
    "        ('estou tremendo de medo', 'medo'),\n",
    "        ('eu tenho muito medo dele', 'medo'),\n",
    "        ('estou com medo do resultado dos meus testes', 'medo')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remoção stop words - Froma manual\n",
    "stopwords = ['a', 'agora', 'algum', 'alguma', 'aquele', 'aqueles', 'de', 'deu', 'do', 'e', 'estou', 'esta', 'esta',\n",
    "             'ir', 'meu', 'muito', 'mesmo', 'no', 'nossa', 'o', 'outro', 'para', 'que', 'sem', 'talvez', 'tem', 'tendo',\n",
    "             'tenha', 'teve', 'tive', 'todo', 'um', 'uma', 'umas', 'uns', 'vou']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StopWords NLTK\n",
    "stopwordsnltk = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['admirada', 'muitos'], 'alegria'), (['sinto', 'completamente', 'amado'], 'alegria'), (['amar', 'maravilhoso'], 'alegria'), (['sentindo', 'animado', 'novamente'], 'alegria'), (['bem', 'hoje'], 'alegria'), (['belo', 'dia', 'dirigir', 'carro', 'novo'], 'alegria'), (['dia', 'bonito'], 'alegria'), (['contente', 'resultado', 'teste', 'fiz', 'dia', 'ontem'], 'alegria'), (['amor', 'lindo'], 'alegria'), (['amizade', 'amor', 'vai', 'durar', 'sempre'], 'alegria'), (['amedrontado'], 'medo'), (['ameacando', 'dias'], 'medo'), (['deixa', 'apavorada'], 'medo'), (['lugar', 'apavorante'], 'medo'), (['perdermos', 'outro', 'jogo', 'eliminados', 'deixa', 'pavor'], 'medo'), (['tome', 'cuidado', 'lobisomem'], 'medo'), (['descobrirem', 'encrencados'], 'medo'), (['tremendo', 'medo'], 'medo'), (['medo'], 'medo'), (['medo', 'resultado', 'testes'], 'medo')]\n"
     ]
    }
   ],
   "source": [
    "def remove_stop_words(texto):\n",
    "    frases = []\n",
    "    for (palavras, emocao) in texto:\n",
    "        semstop = [p for p in palavras.split() if p not in stopwordsnltk]\n",
    "        frases.append((semstop, emocao))\n",
    "    return frases\n",
    "\n",
    "print(remove_stop_words(base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['admir', 'muit'], 'alegria'), (['sint', 'complet', 'am'], 'alegria'), (['am', 'maravilh'], 'alegria'), (['sent', 'anim', 'nov'], 'alegria'), (['bem', 'hoj'], 'alegria'), (['bel', 'dia', 'dirig', 'carr', 'nov'], 'alegria'), (['dia', 'bonit'], 'alegria'), (['cont', 'result', 'test', 'fiz', 'dia', 'ont'], 'alegria'), (['am', 'lind'], 'alegria'), (['amizad', 'am', 'vai', 'dur', 'sempr'], 'alegria'), (['amedront'], 'medo'), (['ameac', 'dia'], 'medo'), (['deix', 'apavor'], 'medo'), (['lug', 'apavor'], 'medo'), (['perd', 'outr', 'jog', 'elimin', 'deix', 'pav'], 'medo'), (['tom', 'cuid', 'lobisom'], 'medo'), (['descobr', 'encrenc'], 'medo'), (['trem', 'med'], 'medo'), (['med'], 'medo'), (['med', 'result', 'test'], 'medo')]\n"
     ]
    }
   ],
   "source": [
    "#Stemer\n",
    "def aplicastemer(texto):\n",
    "    stemer = nltk.stem.RSLPStemmer()\n",
    "    frases_com_stemer = []\n",
    "    for (palavras, emocao) in texto:\n",
    "        com_stemer = [str(stemer.stem(p)) for p in palavras.split() if p not in stopwordsnltk]\n",
    "        frases_com_stemer.append((com_stemer, emocao))\n",
    "    return frases_com_stemer\n",
    "\n",
    "frases_com_steming = aplicastemer(base)\n",
    "print(frases_com_steming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admir', 'muit', 'sint', 'complet', 'am', 'am', 'maravilh', 'sent', 'anim', 'nov', 'bem', 'hoj', 'bel', 'dia', 'dirig', 'carr', 'nov', 'dia', 'bonit', 'cont', 'result', 'test', 'fiz', 'dia', 'ont', 'am', 'lind', 'amizad', 'am', 'vai', 'dur', 'sempr', 'amedront', 'ameac', 'dia', 'deix', 'apavor', 'lug', 'apavor', 'perd', 'outr', 'jog', 'elimin', 'deix', 'pav', 'tom', 'cuid', 'lobisom', 'descobr', 'encrenc', 'trem', 'med', 'med', 'med', 'result', 'test']\n"
     ]
    }
   ],
   "source": [
    "def busca_palavras(frase):\n",
    "    todas_palavras = []\n",
    "    for (palavras, emocao) in frase:\n",
    "        todas_palavras.extend(palavras)\n",
    "    return todas_palavras\n",
    "\n",
    "palavras = busca_palavras(frases_com_steming)\n",
    "print(palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 primeiras palavras:  [('am', 4), ('dia', 4), ('med', 3), ('nov', 2), ('result', 2), ('test', 2), ('deix', 2), ('apavor', 2), ('admir', 1), ('muit', 1), ('sint', 1), ('complet', 1), ('maravilh', 1), ('sent', 1), ('anim', 1), ('bem', 1), ('hoj', 1), ('bel', 1), ('dirig', 1), ('carr', 1), ('bonit', 1), ('cont', 1), ('fiz', 1), ('ont', 1), ('lind', 1), ('amizad', 1), ('vai', 1), ('dur', 1), ('sempr', 1), ('amedront', 1), ('ameac', 1), ('lug', 1), ('perd', 1), ('outr', 1), ('jog', 1), ('elimin', 1), ('pav', 1), ('tom', 1), ('cuid', 1), ('lobisom', 1), ('descobr', 1), ('encrenc', 1), ('trem', 1)]\n"
     ]
    }
   ],
   "source": [
    "#Encontrar palavras repetidas\n",
    "def busca_frequencia(palavras):\n",
    "    palavras = nltk.FreqDist(palavras)\n",
    "    return palavras\n",
    "\n",
    "frequencia = busca_frequencia(palavras)\n",
    "print('50 primeiras palavras: ', frequencia.most_common(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['admir', 'muit', 'sint', 'complet', 'am', 'maravilh', 'sent', 'anim', 'nov', 'bem', 'hoj', 'bel', 'dia', 'dirig', 'carr', 'bonit', 'cont', 'result', 'test', 'fiz', 'ont', 'lind', 'amizad', 'vai', 'dur', 'sempr', 'amedront', 'ameac', 'deix', 'apavor', 'lug', 'perd', 'outr', 'jog', 'elimin', 'pav', 'tom', 'cuid', 'lobisom', 'descobr', 'encrenc', 'trem', 'med'])\n"
     ]
    }
   ],
   "source": [
    "def busca_palavras_unicas(frequencia):\n",
    "    freq = frequencia.keys()\n",
    "    return freq\n",
    "\n",
    "palavras_unicas = busca_palavras_unicas(frequencia)\n",
    "print(palavras_unicas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'admir': False, 'muit': False, 'sint': False, 'complet': False, 'am': True, 'maravilh': False, 'sent': False, 'anim': False, 'nov': True, 'bem': False, 'hoj': False, 'bel': False, 'dia': True, 'dirig': False, 'carr': False, 'bonit': False, 'cont': False, 'result': False, 'test': False, 'fiz': False, 'ont': False, 'lind': False, 'amizad': False, 'vai': False, 'dur': False, 'sempr': False, 'amedront': False, 'ameac': False, 'deix': False, 'apavor': False, 'lug': False, 'perd': False, 'outr': False, 'jog': False, 'elimin': False, 'pav': False, 'tom': False, 'cuid': False, 'lobisom': False, 'descobr': False, 'encrenc': False, 'trem': False, 'med': False}\n"
     ]
    }
   ],
   "source": [
    "def extrator_de_palavars(documento):\n",
    "    doc = set(documento)\n",
    "    caracteristicas = {}\n",
    "    for palavras in palavras_unicas:\n",
    "        caracteristicas['%s' % palavras] = (palavras in doc)\n",
    "    return caracteristicas\n",
    "\n",
    "caracteristicas_frases = extrator_de_palavars(['am', 'nov','dia'])\n",
    "print(caracteristicas_frases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'admir': True, 'muit': True, 'sint': False, 'complet': False, 'am': False, 'maravilh': False, 'sent': False, 'anim': False, 'nov': False, 'bem': False, 'hoj': False, 'bel': False, 'dia': False, 'dirig': False, 'carr': False, 'bonit': False, 'cont': False, 'result': False, 'test': False, 'fiz': False, 'ont': False, 'lind': False, 'amizad': False, 'vai': False, 'dur': False, 'sempr': False, 'amedront': False, 'ameac': False, 'deix': False, 'apavor': False, 'lug': False, 'perd': False, 'outr': False, 'jog': False, 'elimin': False, 'pav': False, 'tom': False, 'cuid': False, 'lobisom': False, 'descobr': False, 'encrenc': False, 'trem': False, 'med': False}, 'alegria')\n"
     ]
    }
   ],
   "source": [
    "base_completa = nltk.classify.apply_features(extrator_de_palavars, frases_com_steming)\n",
    "print(base_completa[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alegria', 'medo']\n",
      "Most Informative Features\n",
      "                     dia = True           alegri : medo   =      2.3 : 1.0\n",
      "                      am = False            medo : alegri =      1.6 : 1.0\n",
      "                     med = False          alegri : medo   =      1.4 : 1.0\n",
      "                     dia = False            medo : alegri =      1.3 : 1.0\n",
      "                  apavor = False          alegri : medo   =      1.2 : 1.0\n",
      "                    deix = False          alegri : medo   =      1.2 : 1.0\n",
      "                     nov = False            medo : alegri =      1.2 : 1.0\n",
      "                   admir = False            medo : alegri =      1.1 : 1.0\n",
      "                   ameac = False          alegri : medo   =      1.1 : 1.0\n",
      "                amedront = False          alegri : medo   =      1.1 : 1.0\n",
      "                  amizad = False            medo : alegri =      1.1 : 1.0\n",
      "                    anim = False            medo : alegri =      1.1 : 1.0\n",
      "                     bel = False            medo : alegri =      1.1 : 1.0\n",
      "                     bem = False            medo : alegri =      1.1 : 1.0\n",
      "                   bonit = False            medo : alegri =      1.1 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Naive Bases - constroi tab de probabilidade\n",
    "classificador = nltk.NaiveBayesClassifier.train(base_completa)\n",
    "print(classificador.labels())\n",
    "print(classificador.show_most_informative_features(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medo\n"
     ]
    }
   ],
   "source": [
    "teste = 'estou com medo'\n",
    "teste_steming = []\n",
    "stemer = nltk.stem.RSLPStemmer()\n",
    "for (palavras) in teste.split():\n",
    "    comstem = [p for p in palavras.split()]\n",
    "    teste_steming.append(str(stemer.stem(comstem[0])))\n",
    "\n",
    "novo = extrator_de_palavars(teste_steming)\n",
    "print(classificador.classify(novo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alegria: 0.041046\n",
      "medo: 0.958954\n"
     ]
    }
   ],
   "source": [
    "distribuicao = classificador.prob_classify(novo)\n",
    "for classe in distribuicao.samples():\n",
    "    print('%s: %f' % (classe, distribuicao.prob(classe)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
